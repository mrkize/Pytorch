path:
  data_path: '../data/cifar10/'
  result_path: results/VIT_Model_cifar10/
  model_path: Network/VIT_Model_cifar10/

patch:
  image_size: 32
  patch_size: 8
  num_patches: 196
  num_classes: 100
  embed_dim: 192
  depth: 4
  heads: 8
  mlp_dim: 512
  dropout: 0.1
  emb_dropout: 0.1

general:
  use_cuda: Yes
  seed_target: 1001
  seed_shadow: 101
  public_data_seed: 404
  train_target_size: 30000 # 2 500, 5 000, 10 000, 15 000 // 4 600, 10 520, 19 920, 29 540
  test_target_size: 30000
  number_shadow_model: 128 # 25 50 MNIST ou 100 cifar

learning:
  batch_size: 64
  learning_rate: 0.01
  momentum: 0.9
  epochs: 100 #25 max 100 cifar10, 200 sinon
  decrease_lr_factor: 0.5
  decrease_lr_every: 50
  ml:
    reg_lambd: 10
    n_estimators: 10000

statistics:
  dataset: CIFAR10 #MNIST // CIFAR10 // CIFAR100
  type: overfitting #training_size // number_shadow // overfitting
  training_size_value: [4600, 10520, 19920, 29540] #[2500, 5000, 10000, 15000] #4 600, 10 520, 19 920, 29 540
  number_shadow_value: [100] #[2, 10 ,20, 50, 100]
  epoch_value: [100] #[2, 10 ,20, 50, 100]

train:
    warmup_epoch: 20
    jigsaw: 0.5
    num_masking_patches: 8
    min_num_patches: 2
